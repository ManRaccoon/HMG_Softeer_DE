# 20250821 Wiki

## 데일리 스크럼

- 팀원들과 일단 모델 성능은 신경쓰지 않고 완성하자고 이야기하였다.

## 리뷰

- 데이터 프로세스 자체를 빠르게 진행해보기 위해 Glue를 이용한 pyspark Job을 만들어 실행해보았고 이를 S3와 연결하여 S3에 데이터가 추가되면 이를 Crawler로 가져와 데이터 처리 후 다시 S3 outputs/ 디렉토리에 넣는 작업을 만들었다.

- 이후에는 크롤러, Slack알림 등을 연결하여 전체적인 과정이 정상적으로 작동하는 지 확인해 볼 예정이다

## 회고

- 프로덕트의 진행 과정에서 해당하는 DB의 역할이 무엇인지 정확히 파악하고 가장 비용 효율적인 데이터베이스를 S3, DynamoDB, RDS 중에서 고르는 훈련을 하자