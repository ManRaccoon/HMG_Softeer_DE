# 20250728 Wiki

## 데일리 스크럼

- 지금까지의 미션이 어땠는지 이야기하고, 그동안 배운 것, 앞으로의 미션에 대한 마음가짐을 서로 나눴다.

## 리뷰

- 며칠동안 고생해서 Dockerfile만 빌드하고, Hadoop과 Yarn에 대해 공부한 보람이 있는 것 같다. 비슷한 구조의 Spark를 학습했는데 어렵지 않게 구조를 파악하고 코드에 적용해 볼 수 있었다. 물론 정확한 코드에 대해서는 다시 학습 해야한다..

- Spark Driver와 Executor, Cluster manager의 Driver, Worker에 대한 개념이 살짝 헷갈렸었는데 Spark는 관련한 책을 통해 필요한 부분을 학습하였더니 학습 속도가 굉장히 빨랐다. 기존 Hadoop의 resource, node manager 구조와 비슷했고 이를 쉽게 정리해놓은 책 때문에 쉽게 적용할 수 있지 않았나 싶다.

- 이전에 학습한 요소도 있어서 결과론적인 이야기이지만 새로운 지식을 빠르게 학습할 때에는 개념을 알려주는 책을 통해 필요한 부분을 학습한 후에 공식문서, 인터넷, GPT를 활용하는 것이 좋아보인다.

왜 그렇냐면

1. 공식문서 : 우선 영어독해가 그렇게 빠르지 않고, 생각보다 깔끔하게 정리되어있지 않아 처음 공부를 할 때 해석 및 이해가 오래 걸린다. 버전이 바뀌어 새로운 메소드가 나올 경우 사용하는 것이 좋다고 판단했다.

2. 인터넷 : 처음 공부하기에 너무 개인화가 심하다. 개념을 정리하는 블로그도 자신이 이해한 대로 적기 때문에 뒤죽박죽이고, 실제 코드도 자신이 만들고 싶은 코드의 결과물을 올려놓은 것이기 때문에 내 문제에 적용하기 어려웠다. 필요한 지식이 군데군데 빠져있지만, 잘 정리되어있는 곳도 많으므로, 책으로 학습한 이후 깔끔하게 정리하는 용으로 블로그의 글이나 사진을 보면 정리하기에 좋을 것이라고 판단했다.

3. GPT : 자료가 많이 없는 기술에 대해 Hallucination이 너무 심해서 잘못된 정보를 판별할 능력이 없는 사람이 공부하기에 최악의 툴이었다. 기본적으로 학습이 진행된 이후에 로그를 통한 디버깅을 할 때 사용하면 좋을 것이라고 판단했다.

## 회고

- 빅데이터 프로젝트 내에서 Spark가 사용된 부분을 30분동안 보자

- 이 기술의 스택이 아얘 처음일 때는 한국어로 쓰여진 기초 책을 먼저 보고 감을 찾은 후에 인터넷의 정리를 보자. 이 글과 그림을 왜 그렸는지 이해가 될 것이다.